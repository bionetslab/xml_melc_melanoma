{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aacb9d1-181f-4064-9069-c75d67a67a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 13:39:52.687057: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-05 13:39:52.700896: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 13:39:52.717506: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 13:39:52.722387: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 13:39:52.734714: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-05 13:39:53.601301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base = \"/data/bionets\" if \"ramses\" in os.uname()[1] else \"/data_nfs/\"\n",
    "\n",
    "import cv2 \n",
    "import sys\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "sys.path.append(\"..\")\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5becc9-7c58-4f2d-9d1f-aa58dfd8e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf060dfa-3ce7-4599-a7ae-cb3be07c9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"../config.json\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "    \n",
    "dataset_statistics = configs[\"dataset_statistics\"]\n",
    "checkpoint_path = configs[\"downloaded_model_weights\"]\n",
    "pretrained_model_path = configs[\"pretrained_model_path\"]\n",
    "roi_save_path = configs[\"PFS_ROIs\"]\n",
    "finetuned_models_path = configs[\"finetuned_models\"]\n",
    "segmentation_results = configs[\"segmentation_results\"]\n",
    "\n",
    "with open(os.path.join(configs[\"dataset_statistics\"], \"melanoma_means.json\"), \"r\") as f:\n",
    "    markers = json.load(f).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8c544c-60b2-4243-b804-6c1902b5797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data_nfs/je30bery/melanoma_data/data/ROIs_new/\n"
     ]
    }
   ],
   "source": [
    "print(roi_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9159f9b7-eedb-4d58-b9b7-5f016dd9e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data_csv(high_quality_only=True, pfs=True, config_path=config_path)\n",
    "data = data.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b111311-b12c-48e1-8641-be6891f1fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {0: [16],\n",
    " 1: [29],\n",
    " 2: [33],\n",
    " 3: [8, 15, 18, 19, 20],\n",
    " 4: [25],\n",
    " 5: [9],\n",
    " 6: [21],\n",
    " 7: [5],\n",
    " 8: [30],\n",
    " 9: [17],\n",
    " 10: [3],\n",
    " 11: [26],\n",
    " 12: [32],\n",
    " 13: [4],\n",
    " 14: [24],\n",
    " 15: [11, 12],\n",
    " 16: [0],\n",
    " 17: [7],\n",
    " 18: [22, 34],\n",
    " 19: [28],\n",
    " 20: [27],\n",
    " 21: [6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f30c2c77-3ede-4e53-b46a-1bd952a99bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 22/22 [20:59<00:00, 57.26s/it]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18_smoothgrad(indim=len(markers), cam=True, checkpoint_path=checkpoint_path)\n",
    "model = model.to(\"cuda:0\")\n",
    "finetuned_models = os.listdir(finetuned_models_path)\n",
    "gcs = list()\n",
    "filepaths = list()\n",
    "for split in tqdm(splits):\n",
    "    data_subset = data[data[\"Histo ID\"].isin(splits[split])]\n",
    "    if len(data_subset) == 0:\n",
    "        continue\n",
    "    filepaths.append(data_subset[\"Sample\"].values)\n",
    "    dl = t.utils.data.DataLoader(MelanomaData(markers, pretrain=False, data=data_subset, mode=\"val\", config_path=config_path), batch_size=1, shuffle=False)\n",
    "    model_path = [m for m in finetuned_models if f\"split={split}\" in m][0]\n",
    "    model.load_state_dict(t.load(os.path.join(finetuned_models_path, model_path), map_location=\"cuda:0\"), strict=True)\n",
    "    model.eval()\n",
    "    noise_correction = get_smooth_grad(None, model, cuda=True, n_smooth=20, noise_std=0.15)\n",
    "    corrector = np.mean(noise_correction, axis=-1)\n",
    "    gc = get_smooth_grad(dl, model, cuda=True, n_smooth=10, noise_std=0.15)\n",
    "    for i in range(gc.shape[-1]):\n",
    "        gradcam = gc[:,:,i] \n",
    "        gradcam /= np.max(gradcam)\n",
    "        corrected = gradcam - corrector\n",
    "        corrected = np.where(corrected > 0, corrected, 0)\n",
    "        gcs.append(corrected)\n",
    "filepaths = np.concatenate(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "775a4903-b44a-4975-bdfa-7d7d02699099",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath, gc in zip(filepaths, gcs):\n",
    "    segmented = os.path.join(segmentation_results, f'{filepath}_cell.npy')\n",
    "    with open(segmented, \"rb\") as openfile:\n",
    "        seg_file = np.load(openfile)\n",
    "    img, roi_cells = get_binary(gc, seg_file, output_size=512, cutoff=0.9)\n",
    "    os.makedirs(roi_save_path, exist_ok=True)\n",
    "    with open(os.path.join(roi_save_path, filepath + \"_idxs.pkl\"), \"wb\") as fp:\n",
    "        pickle.dump(roi_cells, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca2d0e-ebd8-4232-81c7-73dedf21078b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
